training:
  epochs: 100
  batch_size: 2  # Reduced for faster backward pass on CPU (2x faster than 8)
                  # Use gradient_accumulation_steps: 4 to maintain effective batch_size=8
                  # For GPU training, you can use larger batch sizes (16-32)
  learning_rate: 0.01
  momentum: 0.937
  weight_decay: 0.0005
  warmup_epochs: 3
  warmup_momentum: 0.8
  warmup_bias_lr: 0.1
  lr_schedule: cosine  # Options: linear, cosine
  optimizer: SGD  # Options: SGD, Adam, AdamW
  gradient_clip: 10.0
  gradient_accumulation_steps: 4  # Accumulate gradients over 4 batches (effective batch_size = 2*4 = 8)

data:
  root_dir: "data"  # Relative path to data directory
  datasets:
    - name: smod
      splits:
        train: "smod/annotations/instances_train.json"
        val: "smod/annotations/instances_val.json"
        test: "smod/annotations/instances_test.json"
    - name: hit_uav
      splits:
        train: "hit_uav/annotations/instances_train.json"
        val: "hit_uav/annotations/instances_val.json"
        test: "hit_uav/annotations/instances_test.json"
    - name: dronergbt
      splits:
        train: "dronergbt/annotations/instances_train.json"
        val: "dronergbt/annotations/instances_val.json"
        test: "dronergbt/annotations/instances_test.json"
  img_size: 256  # Further reduced for 6.25x speedup from 640 (640^2 / 256^2 = 6.25)
                  # Can increase to 320, 416 or 640 for better accuracy
  num_workers: 4  # Optimized for speed - use 0 on macOS, 4-8 for Linux/Colab

augmentation:
  mosaic: false  # Disabled for faster training (mosaic is expensive)
  mixup: false
  mosaic_prob: 0.0
  mixup_prob: 0.0

logging:
  log_dir: "experiments/logs"
  tensorboard_dir: "experiments/tensorboard"
  checkpoint_dir: "checkpoints"  # Relative path for local, use "/content/drive/MyDrive/yolo_checkpoints" for Colab
  save_freq: 10  # Save checkpoint every 10 epochs
  log_freq: 200  # Reduced logging frequency for faster training

evaluation:
  eval_freq: 5  # Evaluate less frequently for faster training
  conf_thres: 0.5
  iou_thres: 0.5
