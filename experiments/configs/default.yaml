training:
  epochs: 100
  batch_size: 4  # Increased for better CPU utilization and faster training
                 # Larger batches = fewer iterations = faster epoch time
                 # For GPU training, you can use larger batch sizes (16–32)
  learning_rate: 0.01
  momentum: 0.937
  weight_decay: 0.0005
  warmup_epochs: 3
  warmup_momentum: 0.8
  warmup_bias_lr: 0.1
  lr_schedule: cosine   # Options: linear, cosine
  optimizer: SGD        # Options: SGD, Adam, AdamW
  gradient_clip: 10.0

data:
  root_dir: "data"  # Relative path to data directory
  datasets:
    - name: smod
      splits:
        train: "smod/annotations/instances_train.json"
        val: "smod/annotations/instances_val.json"
        test: "smod/annotations/instances_test.json"
    - name: hit_uav
      splits:
        train: "hit_uav/annotations/instances_train.json"
        val: "hit_uav/annotations/instances_val.json"
        test: "hit_uav/annotations/instances_test.json"
    - name: dronergbt
      splits:
        train: "dronergbt/annotations/instances_train.json"
        val: "dronergbt/annotations/instances_val.json"
        test: "dronergbt/annotations/instances_test.json"
  img_size: 416   # Reduced from 640 for ~2.4× speedup
  num_workers: 2  # Set to 0 on macOS to avoid multiprocessing overhead

augmentation:
  mosaic: false  # Disabled for faster training (mosaic is expensive)
  mixup: false
  mosaic_prob: 0.0
  mixup_prob: 0.0

logging:
  log_dir: "experiments/logs"
  tensorboard_dir: "experiments/tensorboard"
  checkpoint_dir: "/content/drive/MyDrive/yolo_checkpoints"
  save_freq: 10   # Save checkpoint every 10 epochs
  log_freq: 100   # Log training metrics every 100 iterations

evaluation:
  eval_freq: 5    # Evaluate on validation set every epoch
  conf_thres: 0.5
  iou_thres: 0.5


device: cuda      # Options: cuda, cpu
